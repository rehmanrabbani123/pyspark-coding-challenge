{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3af61a1-76c7-4103-9cfc-bef512fcfacc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, BooleanType, TimestampType, DateType\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"Data Generation\").getOrCreate()\n",
    "\n",
    "def random_date(start, end):\n",
    "    \"\"\"Generate a random datetime between `start` and `end`.\"\"\"\n",
    "    return start + timedelta(\n",
    "        seconds=random.randint(0, int((end - start).total_seconds())))\n",
    "\n",
    "# Generate test data for the last 7-day period.\n",
    "start_date = datetime.now() - timedelta(days=7)\n",
    "end_date = datetime.now()\n",
    "\n",
    "def make_items(base_item_id):\n",
    "    \"\"\"Generate a list of 10 items with random order flag.\"\"\"\n",
    "    items = []\n",
    "    # Randomly decide how many items to mark as ordered (between 1 and 3)\n",
    "    num_ordered_items = random.randint(1, 3)\n",
    "    # Randomly choose indices to mark as ordered\n",
    "    ordered_indices = random.sample(range(10), num_ordered_items)\n",
    "\n",
    "    for i in range(10):\n",
    "        items.append({\n",
    "            \"item_id\": base_item_id + i,\n",
    "            \"is_order\": (i in ordered_indices)  # randomly mark items as ordered\n",
    "        })\n",
    "    return items\n",
    "  \n",
    "def generate_impressions():\n",
    "    impressions_schema = StructType([\n",
    "        StructField(\"dt\", StringType(), False),\n",
    "        StructField(\"ranking_id\", StringType(), False),\n",
    "        StructField(\"customer_id\", IntegerType(), False),\n",
    "        StructField(\"impressions\", ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"item_id\", IntegerType(), False),\n",
    "                StructField(\"is_order\", BooleanType(), False)\n",
    "            ])\n",
    "        ), False)\n",
    "    ])\n",
    "  \n",
    "    impressions_data = [{\"dt\": (start_date + timedelta(days=i % 7)).strftime(\"%Y-%m-%d\"),\n",
    "                         \"ranking_id\": f\"r{i}\",\n",
    "                         \"customer_id\": random.randint(1000, 1020),\n",
    "                         \"impressions\": make_items(200 + i * 10)} for i in range(10)]\n",
    "\n",
    "    impressions_df = spark.createDataFrame(impressions_data, schema=impressions_schema)\n",
    "    return impressions_df\n",
    "  \n",
    "def generate_clicks():\n",
    "    clicks_schema = StructType([\n",
    "        StructField(\"dt\", StringType(), False),\n",
    "        StructField(\"customer_id\", IntegerType(), False),\n",
    "        StructField(\"item_id\", IntegerType(), False),\n",
    "        StructField(\"click_time\", TimestampType(), False)\n",
    "    ])\n",
    "\n",
    "    clicks_data = [{\"dt\": (start_date + timedelta(days=i % 7)).strftime(\"%Y-%m-%d\"),\n",
    "                    \"customer_id\": random.randint(1000, 1020),\n",
    "                    \"item_id\": random.randint(200, 210),\n",
    "                    \"click_time\": random_date(start_date, end_date)} for i in range(10)]\n",
    "\n",
    "    clicks_df = spark.createDataFrame(clicks_data, schema=clicks_schema)\n",
    "    return clicks_df\n",
    "\n",
    "def generate_add_to_cart():\n",
    "    \"\"\"Generate a DataFrame for sample 'add to cart' data.\"\"\"\n",
    "    add_to_cart_schema = StructType([\n",
    "        StructField(\"dt\", StringType(), nullable=False),\n",
    "        StructField(\"customer_id\", IntegerType(), nullable=False),\n",
    "        StructField(\"config_id\", IntegerType(), nullable=False),\n",
    "        StructField(\"simple_id\", IntegerType(), nullable=False),\n",
    "        StructField(\"occurred_at\", TimestampType(), nullable=False)\n",
    "    ])\n",
    "\n",
    "    add_to_cart_data = [\n",
    "        {\n",
    "            \"dt\": (start_date + timedelta(days=i % 7)).strftime(\"%Y-%m-%d\"),\n",
    "            \"customer_id\": random.randint(1000, 1020),\n",
    "            \"config_id\": random.randint(200, 210),\n",
    "            \"simple_id\": random.randint(1, 5),\n",
    "            \"occurred_at\": random_date(start_date, end_date)\n",
    "        }\n",
    "        for i in range(10)\n",
    "    ]\n",
    "\n",
    "    add_to_cart_df = spark.createDataFrame(add_to_cart_data, schema=add_to_cart_schema)\n",
    "    return add_to_cart_df\n",
    "  \n",
    "def generate_previous_orders():\n",
    "    \"\"\"Generate a DataFrame for sample previous orders data.\"\"\"\n",
    "    previous_orders_schema = StructType([\n",
    "        StructField(\"order_date\", DateType(), nullable=False),\n",
    "        StructField(\"customer_id\", IntegerType(), nullable=False),\n",
    "        StructField(\"config_id\", IntegerType(), nullable=False),\n",
    "        StructField(\"simple_id\", IntegerType(), nullable=False),\n",
    "        StructField(\"occurred_at\", TimestampType(), nullable=False)\n",
    "    ])\n",
    "\n",
    "    previous_orders_data = [\n",
    "        {\n",
    "            \"order_date\": (start_date + timedelta(days=i % 7)).date(),\n",
    "            \"customer_id\": random.randint(1000, 1020),\n",
    "            \"config_id\": random.randint(200, 210),\n",
    "            \"simple_id\": random.randint(1, 5),\n",
    "            \"occurred_at\": random_date(start_date, end_date)\n",
    "        }\n",
    "        for i in range(10)\n",
    "    ]\n",
    "\n",
    "    previous_orders_df = spark.createDataFrame(previous_orders_data, schema=previous_orders_schema)\n",
    "    return previous_orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebb5988b-6c3b-4afa-b085-98241fb3db74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "data_generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}